---
title: "Median-odds-ratio"
author: "Steve Simon"
date: "May 10, 2017"
output: html_document
---

This program explores the median odds ratio, a measure of the size of a random effect in a random effects logistic regression model.

```{r preliminaries}
library(broom)
library(dplyr)
library(ggplot2)
library(lme4)
library(magrittr)
```

This data set represents the number of cancer cells out of 400 that were killed by a radiation exposure. There were 27 experiments run, 3 per day across 9 different days.

```{r read-data}
f <- "http://www.statsci.org/data/general/radiatio.txt"
radiation <- read.table(file=f, header=TRUE)
radiation %<>% mutate(p=Survived/400) %>% mutate(label="Raw data")
print(radiation)
summary(radiation$p)
```

Let's plot the data, ignoring the day.

```{r plot, fig.width=7, fig.height=1}
radiation                                       %>%
  ggplot(aes(label, p))                          +
  geom_boxplot()                                 +
  expand_limits(y=c(0,1))                        +
  coord_flip()
```

It may not be obvious, but the data you are looking at is too variable to come from a binomial distribution.

```{r compare-to-simulation, fig.width=7, fig.height=1.33}
n <- dim(radiation)[1]
simulated_binomial <- rbinom(n, 400, mean(radiation$p))/400
tibble(p=simulated_binomial,
  label="Simulated binomial")                   %>%
  bind_rows(radiation)                          %>%
  ggplot(aes(label, p))                          +
  geom_boxplot()                                 +
  expand_limits(y=c(0,1))                        +
  coord_flip()



```

A plot of the probabilities by day shows why the data is more variable than the simulation.

```{r scatterplot, fig.width=4, fig.height=4}
radiation                                       %>%
  ggplot(aes(factor(Occasion), p))                       +
  expand_limits(y=c(0,1))                                +
  geom_point()
```

There is significant day-to-day variation. How would you model that variation?

```{r glm}
random_days <- glmer(cbind(Survived, 400-Survived) ~ 1 | Occasion, data=radiation, family=binomial)
summary(random_days)
```

The question is how big and important this random effect is. In a linear regression model, you can compute the intraclass correlation, which is a measure of the strength of the correlation between two observations from the same level of the random effect. It is computed as

$\rho=\sigma_B/(\sigma_B+\sigma_W)$

where $\sigma_B$ is the between group standard deviation and $\sigma_W$ is the within group standard deviation. But when you look at the summary output, there is no within group standard deviation. You could use the formula for the standard deviation of a binomial random variable. But this variance is on the probability scale and the between group variance is on the log odds scale.

A new statistic has been proposed, the median odds ratio, for the random effects logistic regression. It is defined as 

$MOR = exp(\sqrt{2}\sigma_B Z_.75)$

You can find a general overview of this statistic at

Juan Merlo, Basile Chaix, Henrik Ohlsson, Anders Beckman, Kristina Johnell, Per Hjerpe, L Råstam, and K Larsen. "A brief conceptual tutorial of multilevel analysis in social epidemiology: using measures of clustering in multilevel logistic regression to investigate contextual phenomena." J Epidemiol Community Health. 2006 Apr; 60(4): 290–297. doi:  10.1136/jech.2004.029454. Available at https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2566165/.

Here's how you would compute this statistic

```{r mor}
random_days                                     %>%
  tidy                                          %>%
  filter(term=="sd_(Intercept).Occasion")       %>%
  select(estimate)                              %>%
  unlist                                        %>%
  unname                                        -> sigma_B
print(sigma_B)
mor <- exp(sqrt(2)*sigma_B*0.6745)
print(mor)
```

The authors claim that this median odds ratio is "the median value of the odds ratio between the area at highest risk and the area at lowest risk when randomly picking out two areas." They should have said "higher" and "lower" but otherwise the interpretation is clear. It's tedious to calculate, but R makes many tedious calculations easy.

```{r all-pairs}
radiation                                       %>%
  group_by(Occasion)                            %>%
  summarize(day_mean=mean(p))                   %>%
  mutate(odds=day_mean/(1-day_mean))            %>%
  arrange(day_mean)                             -> radiation_summary

print(radiation_summary)
n <- dim(radiation_summary)[1]
or_pairs <- rep(NA, n*(n-1)/2)
k <- 0
for (i in 1:(n-1)) {
  for (j in (i+1):n) {
    k <- k+1
    or_pairs[k] <- radiation_summary$odds[j]/radiation_summary$odds[i]
  }
}
summary(or_pairs)
```

Well, that didn't work. Maybe if you look at the raw data rather than the means per day.

```{r recalculate}
radiation %<>% mutate(odds=p/(1-p))
n1 <- 9
n2 <- 3
or_pairs_individual <- rep(NA, n1*(n1-1)/2*n2^2)
chk <- rep("---", n1*(n1-1)/2*n2^2)
k <- 0
for (i1 in 1:(n1-1)) {
  for (j1 in (i1+1):n1) {
    for (i2 in 1:n2) {
      for (j2 in 1:n2) {
        i <- (i1-1)*3+i2
        j <- (j1-1)*3+j2
        k <- k+1
        num <- max(radiation$odds[i], radiation$odds[j])
        den <- min(radiation$odds[i], radiation$odds[j])
        or_pairs_individual[k] <- num/den
        chk[k] <- paste(i1, i2, i, j1, j2, j, sep=", ")
      }
    }
  }
}
summary(or_pairs_individual)
or_pairs_individual
chk
```

# end of file